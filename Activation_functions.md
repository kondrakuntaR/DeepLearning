# Activation Functions
These are usually non linearities.

Some of the activations functions are mentioned below:
1. Sigmoid
2. TanH
3. Maxout
4. ReLU
5. LeakyReLU
6. Exponential Linear Unit

#### Concepts Covered
1. Gain Functions
2. ReLU

## Gain Functions

## ReLU
$\sigma{(x)}=ReLU(x):= max\{0,x\}$

